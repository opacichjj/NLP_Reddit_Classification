{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASOIAF/GoT Reddit Posts - Pt. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a user-agent to access Reddit's content\n",
    "headers = {'User-agent': 'JObot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting our subreddit links to loop through\n",
    "subreddits = ['r/asoiaf/new/.json', 'r/gameofthrones/top/.json?t=all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 1 scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "## setting empty posts list to collect our json 'data'\n",
    "posts = []\n",
    "\n",
    "## looping through the two different subreddits\n",
    "for i in range(len(subreddits)):\n",
    "    \n",
    "    ## setting our after to None to start at the beginning of the thread\n",
    "    after = None\n",
    "    \n",
    "    ## looping through 20 times and collecting 25 posts per loop\n",
    "    for posts_25 in range(20):\n",
    "        \n",
    "        print(posts_25)  ## printing the computed iteration\n",
    "        \n",
    "        if after == None:  ## if statement to check value of 'after'\n",
    "            params = {}    ## setting params to empty dictionary if 'None'\n",
    "        \n",
    "        else:\n",
    "            params = {'after': after}  ## setting our params to the after at the end of each series of posts\n",
    "        \n",
    "        ## creating the url for given subreddit by attaching the looped through subreddit\n",
    "        url = 'https://www.reddit.com/' + subreddits[i]  \n",
    "        \n",
    "        ## using our get request based on url and current params\n",
    "        res = requests.get(url, params = params, headers=headers)\n",
    "        \n",
    "        ## if statement run, if our status code is 200 (good)\n",
    "        if res.status_code == 200:\n",
    "            asoiaf = res.json() ## gathering/assigning json info from our get request\n",
    "\n",
    "            ## extending our list of posts from data in 'children'\n",
    "            posts.extend(asoiaf['data']['children'])\n",
    "\n",
    "            ## setting our after value to\n",
    "            after = asoiaf['data']['after']\n",
    "\n",
    "        ## if error with status code, we will break our loop and print error code\n",
    "        else:\n",
    "            print(res.status_code)  \n",
    "            break\n",
    "\n",
    "        time.sleep(1) ## slowing our loop by one second for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1004"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## showing that we have 1004 unique posts\n",
    "len(set([p['data']['name'] for p in posts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['approved_at_utc', 'subreddit', 'selftext', 'author_fullname', 'saved', 'mod_reason_title', 'gilded', 'clicked', 'title', 'link_flair_richtext', 'subreddit_name_prefixed', 'hidden', 'pwls', 'link_flair_css_class', 'downs', 'thumbnail_height', 'hide_score', 'name', 'quarantine', 'link_flair_text_color', 'author_flair_background_color', 'subreddit_type', 'ups', 'total_awards_received', 'media_embed', 'thumbnail_width', 'author_flair_template_id', 'is_original_content', 'user_reports', 'secure_media', 'is_reddit_media_domain', 'is_meta', 'category', 'secure_media_embed', 'link_flair_text', 'can_mod_post', 'score', 'approved_by', 'thumbnail', 'edited', 'author_flair_css_class', 'author_flair_richtext', 'gildings', 'content_categories', 'is_self', 'mod_note', 'created', 'link_flair_type', 'wls', 'banned_by', 'author_flair_type', 'domain', 'allow_live_comments', 'selftext_html', 'likes', 'suggested_sort', 'banned_at_utc', 'view_count', 'archived', 'no_follow', 'is_crosspostable', 'pinned', 'over_18', 'all_awardings', 'media_only', 'link_flair_template_id', 'can_gild', 'spoiler', 'locked', 'author_flair_text', 'visited', 'num_reports', 'distinguished', 'subreddit_id', 'mod_reason_by', 'removal_reason', 'link_flair_background_color', 'id', 'is_robot_indexable', 'report_reasons', 'author', 'num_crossposts', 'num_comments', 'send_replies', 'whitelist_status', 'contest_mode', 'mod_reports', 'author_patreon_flair', 'author_flair_text_color', 'permalink', 'parent_whitelist_status', 'stickied', 'url', 'subreddit_subscribers', 'created_utc', 'discussion_type', 'media', 'is_video'])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## looking at our keys, so that we can isolate our text from the post\n",
    "posts[0]['data'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approved_at_utc': None,\n",
       " 'subreddit': 'asoiaf',\n",
       " 'selftext': \"Welcome to the Weekly Q &amp; A! Feel free to ask any questions you may have about the world of ASOIAF. No need to be bashful. Book and show questions are welcome; please say in your question if you would prefer to focus on the BOOKS, the SHOW, or BOTH.  And if you think you've got an answer to someone's question, feel free to lend them a hand!\",\n",
       " 'author_fullname': 't2_6l4z3',\n",
       " 'saved': False,\n",
       " 'mod_reason_title': None,\n",
       " 'gilded': 0,\n",
       " 'clicked': False,\n",
       " 'title': '(Spoilers Main) Weekly Q and A',\n",
       " 'link_flair_richtext': [{'e': 'text', 't': 'MAIN'}],\n",
       " 'subreddit_name_prefixed': 'r/asoiaf',\n",
       " 'hidden': False,\n",
       " 'pwls': 6,\n",
       " 'link_flair_css_class': 'main',\n",
       " 'downs': 0,\n",
       " 'thumbnail_height': None,\n",
       " 'hide_score': False,\n",
       " 'name': 't3_c8man6',\n",
       " 'quarantine': False,\n",
       " 'link_flair_text_color': 'light',\n",
       " 'author_flair_background_color': '',\n",
       " 'subreddit_type': 'public',\n",
       " 'ups': 11,\n",
       " 'total_awards_received': 0,\n",
       " 'media_embed': {},\n",
       " 'thumbnail_width': None,\n",
       " 'author_flair_template_id': None,\n",
       " 'is_original_content': False,\n",
       " 'user_reports': [],\n",
       " 'secure_media': None,\n",
       " 'is_reddit_media_domain': False,\n",
       " 'is_meta': False,\n",
       " 'category': None,\n",
       " 'secure_media_embed': {},\n",
       " 'link_flair_text': 'MAIN',\n",
       " 'can_mod_post': False,\n",
       " 'score': 11,\n",
       " 'approved_by': None,\n",
       " 'thumbnail': 'self',\n",
       " 'edited': False,\n",
       " 'author_flair_css_class': 'Uthor',\n",
       " 'author_flair_richtext': [{'e': 'text', 't': 'House Marvin'}],\n",
       " 'gildings': {},\n",
       " 'content_categories': None,\n",
       " 'is_self': True,\n",
       " 'mod_note': None,\n",
       " 'created': 1562177258.0,\n",
       " 'link_flair_type': 'richtext',\n",
       " 'wls': 6,\n",
       " 'banned_by': None,\n",
       " 'author_flair_type': 'richtext',\n",
       " 'domain': 'self.asoiaf',\n",
       " 'allow_live_comments': True,\n",
       " 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to the Weekly Q &amp;amp; A! Feel free to ask any questions you may have about the world of ASOIAF. No need to be bashful. Book and show questions are welcome; please say in your question if you would prefer to focus on the BOOKS, the SHOW, or BOTH.  And if you think you&amp;#39;ve got an answer to someone&amp;#39;s question, feel free to lend them a hand!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       " 'likes': None,\n",
       " 'suggested_sort': None,\n",
       " 'banned_at_utc': None,\n",
       " 'view_count': None,\n",
       " 'archived': False,\n",
       " 'no_follow': False,\n",
       " 'is_crosspostable': False,\n",
       " 'pinned': False,\n",
       " 'over_18': False,\n",
       " 'all_awardings': [],\n",
       " 'media_only': False,\n",
       " 'link_flair_template_id': '38bb8770-c904-11e5-8d1c-0e47f9bd707d',\n",
       " 'can_gild': False,\n",
       " 'spoiler': False,\n",
       " 'locked': False,\n",
       " 'author_flair_text': 'House Marvin',\n",
       " 'visited': False,\n",
       " 'num_reports': None,\n",
       " 'distinguished': 'moderator',\n",
       " 'subreddit_id': 't5_2r2o9',\n",
       " 'mod_reason_by': None,\n",
       " 'removal_reason': None,\n",
       " 'link_flair_background_color': '#014980',\n",
       " 'id': 'c8man6',\n",
       " 'is_robot_indexable': True,\n",
       " 'report_reasons': None,\n",
       " 'author': 'AutoModerator',\n",
       " 'num_crossposts': 0,\n",
       " 'num_comments': 79,\n",
       " 'send_replies': False,\n",
       " 'whitelist_status': 'all_ads',\n",
       " 'contest_mode': False,\n",
       " 'mod_reports': [],\n",
       " 'author_patreon_flair': False,\n",
       " 'author_flair_text_color': 'dark',\n",
       " 'permalink': '/r/asoiaf/comments/c8man6/spoilers_main_weekly_q_and_a/',\n",
       " 'parent_whitelist_status': 'all_ads',\n",
       " 'stickied': True,\n",
       " 'url': 'https://www.reddit.com/r/asoiaf/comments/c8man6/spoilers_main_weekly_q_and_a/',\n",
       " 'subreddit_subscribers': 699937,\n",
       " 'created_utc': 1562148458.0,\n",
       " 'discussion_type': None,\n",
       " 'media': None,\n",
       " 'is_video': False}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## showing our first post in posts\n",
    "posts[0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_lists = []\n",
    "for post in range(len(posts)):\n",
    "    post_dict = {}\n",
    "    post_dict['subreddit'] = posts[post]['data']['subreddit']\n",
    "    post_dict['post_text'] = posts[post]['data']['selftext']\n",
    "    \n",
    "    if post_dict['post_text'] != '':\n",
    "        subreddit_lists.append(post_dict)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subreddit': 'gameofthrones',\n",
       " 'post_text': '[SPOILERS] I just remembered there was a scene in seson 7 where john told all the lords to train there women in combat. Because they cant win if only half the population is fighting... where were these women on the battlefield? If i remember well they went to hide in the cripts!!! How could they forget about this??? they the ones writing this line in the first place.'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_lists[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(subreddit_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 2)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 620 entries, 0 to 619\n",
      "Data columns (total 2 columns):\n",
      "post_text    620 non-null object\n",
      "subreddit    620 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('day_1_reddit_scrapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('day_1_reddit_scraping_indexed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 2 scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "afters = []\n",
    "for i in range(len(subreddits)):\n",
    "    after = None\n",
    "    for posts_25 in range(25):\n",
    "        print(posts_25)\n",
    "        if after == None:\n",
    "            params = {}\n",
    "        else:\n",
    "            params = {'after': after}\n",
    "        url = 'https://www.reddit.com/' + subreddits[i]\n",
    "        res = requests.get(url, params = params, headers=headers)\n",
    "        if res.status_code == 200:\n",
    "            asoiaf = res.json()\n",
    "            \n",
    "            ## append will do a list of list, but extend will add to the list\n",
    "            posts.extend(asoiaf['data']['children'])\n",
    "\n",
    "            ## this is where we overwrite it, we start at zero on the first hit\n",
    "            ## then we will set it to a value after\n",
    "            ## now we can hit this API with this 'after' paramater and get 25 more hits every time\n",
    "            after = asoiaf['data']['after']\n",
    "\n",
    "        else:\n",
    "            print(res.status_code)\n",
    "            break\n",
    "\n",
    "        ## slow your loop down intentionally, so you're not hitting the server hard\n",
    "        time.sleep(1) ## slows the loop down by one second for each iteration\n",
    "        afters.append(after) ## collecting our after values to start each successive loop with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1244"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_afters = [afters[24], afters[49]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t3_c1bzp6', 't3_c8205r']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_afters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_collection(subreddit_list):\n",
    "    posts = []\n",
    "    for i in range(len(subreddit_list)):\n",
    "        after = None\n",
    "        for posts_25 in range(40):\n",
    "            if after == None:\n",
    "                params = {}\n",
    "            else:\n",
    "                params = {'after': after}\n",
    "            url = 'https://www.reddit.com/' + subreddit_list[i] \n",
    "            res = requests.get(url, params = params, headers=headers)\n",
    "            if res.status_code == 200:\n",
    "                asoiaf = res.json()\n",
    "\n",
    "                ## append will do a list of list, but extend will add to the list\n",
    "                posts.extend(asoiaf['data']['children'])\n",
    "\n",
    "                ## this is where we overwrite it, we start at zero on the first hit\n",
    "                ## then we will set it to a value after\n",
    "                ## now we can hit this API with this 'after' paramater and get 25 more hits every time\n",
    "                after = asoiaf['data']['after']\n",
    "\n",
    "            else:\n",
    "                print(res.status_code)\n",
    "                break\n",
    "\n",
    "            ## slow your loop down intentionally, so you're not hitting the server hard\n",
    "            time.sleep(2) ## slows the loop down by two seconds for each iteration            \n",
    "    \n",
    "     ## creating a function that will separate the text and the respective subreddit\n",
    "#     def text_parsing(posts):\n",
    "    subreddit_lists = []\n",
    "    for post in range(len(posts)):\n",
    "        post_dict = {}\n",
    "        post_dict['subreddit'] = posts[post]['data']['subreddit']\n",
    "        post_dict['post_text'] = posts[post]['data']['selftext']\n",
    "\n",
    "        if post_dict['post_text'] != '':\n",
    "            subreddit_lists.append(post_dict)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return subreddit_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "new_posts, new_afters = sub_collection(subreddits, recent_afters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t3_c1ohlg', 't3_c7y596']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## afters for #3\n",
    "new_afters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a function that will separate the text and the respective subreddit\n",
    "def text_parsing(posts):\n",
    "    subreddit_lists = []\n",
    "    for post in range(len(posts)):\n",
    "        post_dict = {}\n",
    "        post_dict['subreddit'] = posts[post]['data']['subreddit']\n",
    "        post_dict['post_text'] = posts[post]['data']['selftext']\n",
    "\n",
    "        if post_dict['post_text'] != '':\n",
    "            subreddit_lists.append(post_dict)\n",
    "        else:\n",
    "            pass\n",
    "    return subreddit_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_2 = text_parsing(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## showing the length of collected posts\n",
    "len(posts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to the Weekly Q &amp;amp; A! Feel free to ...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please remember:\\n\\n1. You must submit the ori...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’ll start - “as useless as nipples on a breas...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's been pointed out by Youtuber 'The Dragon ...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In [a recent thread](https://www.reddit.com/r...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           post_text subreddit\n",
       "0  Welcome to the Weekly Q &amp; A! Feel free to ...    asoiaf\n",
       "1  Please remember:\\n\\n1. You must submit the ori...    asoiaf\n",
       "2  I’ll start - “as useless as nipples on a breas...    asoiaf\n",
       "3  It's been pointed out by Youtuber 'The Dragon ...    asoiaf\n",
       "4   In [a recent thread](https://www.reddit.com/r...    asoiaf"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(posts_2)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('day_2_reddit_scrapping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_3 = sub_collection(subreddits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1225"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subreddit': 'gameofthrones',\n",
       " 'post_text': ' We know what D&amp;D did, we know roughly what GRRM would have done, but precisely how would you have made it so, and how would the end result and impact for the viewer have been different? Would the impact really be that different, if Daenerys is still the same in the end?'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_3[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to the Weekly Q &amp;amp; A! Feel free to ...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please remember:\\n\\n1. You must submit the ori...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For me:\\n\\nA Game of Thrones: Ned Stark and *E...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's say fAegon and his army successfully tak...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One time , the king was feasting the queen's f...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           post_text subreddit\n",
       "0  Welcome to the Weekly Q &amp; A! Feel free to ...    asoiaf\n",
       "1  Please remember:\\n\\n1. You must submit the ori...    asoiaf\n",
       "2  For me:\\n\\nA Game of Thrones: Ned Stark and *E...    asoiaf\n",
       "3  Let's say fAegon and his army successfully tak...    asoiaf\n",
       "4  One time , the king was feasting the queen's f...    asoiaf"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(posts_3)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asoiaf           881\n",
       "gameofthrones    344\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('day_3_reddit_scraping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 4 scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1243"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_4 = sub_collection(subreddits)\n",
    "len(posts_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to the Weekly Q &amp;amp; A! Feel free to ...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As you may know, we have a policy against sill...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here I'm not referring to minor gripes about A...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've been rereading the series again, and came...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the books kills multiple highly skilled kni...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           post_text subreddit\n",
       "0  Welcome to the Weekly Q &amp; A! Feel free to ...    asoiaf\n",
       "1  As you may know, we have a policy against sill...    asoiaf\n",
       "2  Here I'm not referring to minor gripes about A...    asoiaf\n",
       "3  I've been rereading the series again, and came...    asoiaf\n",
       "4  In the books kills multiple highly skilled kni...    asoiaf"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame(posts_4)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asoiaf           894\n",
       "gameofthrones    349\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv('day_4_reddit_scraping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 5 scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## changed the subreddit list to include all new posts (no long 'hot')\n",
    "\n",
    "posts_5 = sub_collection(subreddits)\n",
    "len(posts_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just read this in AGOT. I figured the oldest o...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>) for an instant it looked as though he might ...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IIRC either varys or littlefinger suggested to...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As we all know, in asoiaf it is commonly belie...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So we're all aware at this point of how Bronn ...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           post_text subreddit\n",
       "0  Just read this in AGOT. I figured the oldest o...    asoiaf\n",
       "1  ) for an instant it looked as though he might ...    asoiaf\n",
       "2  IIRC either varys or littlefinger suggested to...    asoiaf\n",
       "3  As we all know, in asoiaf it is commonly belie...    asoiaf\n",
       "4  So we're all aware at this point of how Bronn ...    asoiaf"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.DataFrame(posts_5)\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asoiaf           886\n",
       "gameofthrones    381\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv('day_5_reddit_scraping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 6 scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1271"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_6 = sub_collection(subreddits)\n",
    "len(posts_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actually, I have this hunch that somehow Georg...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could be an entire era like the Age of Heroes,...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Westeros has had it's fair share of good and b...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>While re-listening to ACOK much is made of how...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think it is Sansa, she said to Olenna about ...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           post_text subreddit\n",
       "0  Actually, I have this hunch that somehow Georg...    asoiaf\n",
       "1  Could be an entire era like the Age of Heroes,...    asoiaf\n",
       "2  Westeros has had it's fair share of good and b...    asoiaf\n",
       "3  While re-listening to ACOK much is made of how...    asoiaf\n",
       "4  I think it is Sansa, she said to Olenna about ...    asoiaf"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.DataFrame(posts_6)\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asoiaf           886\n",
       "gameofthrones    385\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv('day_6_reddit_scraping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1217"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## scraping the hots section of \n",
    "posts_6 = sub_collection(subreddits)\n",
    "len(posts_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to the Weekly Q &amp;amp; A! Feel free to ...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome to the Weekly Q &amp;amp; A! Feel free to ...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>While re-listening to ACOK much is made of how...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[This comment](https://www.reddit.com/r/asoiaf...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So I was reading Fire and Blood today and duri...</td>\n",
       "      <td>asoiaf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           post_text subreddit\n",
       "0  Welcome to the Weekly Q &amp; A! Feel free to ...    asoiaf\n",
       "1  Welcome to the Weekly Q &amp; A! Feel free to ...    asoiaf\n",
       "2  While re-listening to ACOK much is made of how...    asoiaf\n",
       "3  [This comment](https://www.reddit.com/r/asoiaf...    asoiaf\n",
       "4  So I was reading Fire and Blood today and duri...    asoiaf"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6_hot = pd.DataFrame(posts_6)\n",
    "df6_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11002</th>\n",
       "      <td>Bran just got yeeted out of a fucking wondowsi...</td>\n",
       "      <td>gameofthrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11003</th>\n",
       "      <td>[https://youtu.be/WpeMPIL-mfg](https://youtu.b...</td>\n",
       "      <td>gameofthrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11004</th>\n",
       "      <td>What did people think of Arya’s ending?\\n\\nShe...</td>\n",
       "      <td>gameofthrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11005</th>\n",
       "      <td>It seems like every great house goes extinct s...</td>\n",
       "      <td>gameofthrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>So one thing has always bothered me when i wat...</td>\n",
       "      <td>gameofthrones</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               post_text      subreddit\n",
       "11002  Bran just got yeeted out of a fucking wondowsi...  gameofthrones\n",
       "11003  [https://youtu.be/WpeMPIL-mfg](https://youtu.b...  gameofthrones\n",
       "11004  What did people think of Arya’s ending?\\n\\nShe...  gameofthrones\n",
       "11005  It seems like every great house goes extinct s...  gameofthrones\n",
       "11006  So one thing has always bothered me when i wat...  gameofthrones"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.concat([df6, df6_hot], ignore_index=True)\n",
    "df6.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1265"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## scraping the top for the month\n",
    "posts_6t = sub_collection(subreddits)\n",
    "len(posts_6t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1284"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## scraping the controversial for the past month\n",
    "posts_6c = sub_collection(subreddits)\n",
    "len(posts_6c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18535, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6t = pd.DataFrame(posts_6t)\n",
    "df6c = pd.DataFrame(posts_6c)\n",
    "\n",
    "df6 = pd.concat([df6, df6_hot, df6t, df6c], ignore_index=True)\n",
    "df6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv('day_6_reddit_scraping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 7 scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    }
   ],
   "source": [
    "## pulling our final days worth of subreddits\n",
    "posts_7 = sub_collection(subreddits)\n",
    "df7 = pd.DataFrame(posts_7)\n",
    "print(len(posts_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asoiaf           888\n",
       "gameofthrones    111\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gameofthrones    111\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_asoiaf = df7[df7['subreddit'] == 'gameofthrones']\n",
    "no_asoiaf.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_asoiaf.to_csv('day_7_reddit_scraping.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
